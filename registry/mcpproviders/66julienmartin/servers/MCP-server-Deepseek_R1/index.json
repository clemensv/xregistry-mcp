{
  "repo_ref": "66julienmartin/MCP-server-Deepseek_R1",
  "name": "io.github.66julienmartin/MCP-server-Deepseek_R1",
  "description": "A Model Context Protocol (MCP) server implementation for the Deepseek R1 language model. Deepseek R1 is a powerful language model optimized for reasoning tasks with a context window of 8192 tokens.",
  "version_detail": {
    "version": "1.0.0"
  },
  "remotes": [],
  "registries": [
    {
      "name": "npm",
      "package_name": "@modelcontextprotocol/sdk",
      "license": "",
      "command_arguments": {
        "sub_commands": [],
        "positional_arguments": [
          "/path/to/deepseek-r1-mcp/build/index.js"
        ],
        "environment_variables": [
          {
            "name": "DEEPSEEK_API_KEY",
            "description": "API key for Deepseek R1 model",
            "required": true
          }
        ],
        "named_arguments": null
      }
    }
  ],
  "prompts": [],
  "tools": [
    {
      "name": "deepseek_r1",
      "description": "Generate text using DeepSeek R1 model",
      "inputschema": {
        "type": "object",
        "properties": {
          "prompt": {
            "type": "string",
            "description": "Input text for DeepSeek"
          },
          "max_tokens": {
            "type": "number",
            "description": "Maximum tokens to generate (default: 8192)",
            "minimum": 1,
            "maximum": 8192
          },
          "temperature": {
            "type": "number",
            "description": "Sampling temperature (default: 0.2)",
            "minimum": 0,
            "maximum": 2
          }
        },
        "required": [
          "prompt"
        ]
      }
    }
  ],
  "resources": []
}